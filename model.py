# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-saU33r0eRVeCfj2Xup2_1kQoj3jHnHl
"""

from bs4 import BeautifulSoup

import pandas as pd
import requests
import numpy as np
from zipfile import ZipFile
from io import BytesIO
import matplotlib.pyplot as plt

"""Data Collection

"""
website = 'https://insights.stackoverflow.com/survey'

html_data = requests.get(website)

content = BeautifulSoup(html_data.text, 'html.parser')

# Get the link for latest data:

date_tag = '2023'
data_link = content.find_all('a', {'data-year': date_tag})

data_link = data_link[0].get('href')

# Send an HTTP request to download the zip file
response = requests.get(data_link)

# Check if the request was successful (status code 200)
if response.status_code == 200:
    # Extract the contents of the zip file
    with ZipFile(BytesIO(response.content)) as zip_file:
        # Specify the target directory where you want to extract the files
        target_directory = "/content/drive/MyDrive/Stackoverflow_data"

        # Extract all files from the zip archive
        zip_file.extractall(target_directory)

        print("Zip file extracted successfully.")
else:
    print("Failed to download the zip file. Status code:", response.status_code)

file_path = target_directory + '/survey_results_public.csv'

raw_data = pd.read_csv(file_path)

raw_data.head()

raw_data.info()

df = raw_data[['Country', 'EdLevel', 'YearsCodePro', 'Employment', 'ConvertedCompYearly']]

df = df.rename(columns={'ConvertedCompYearly': 'Salary'})
df.head()

df.info()

df.dropna(subset=['Salary'], inplace=True)

df.info()

df.dropna(inplace=True)
df.isnull().sum()

df['Employment'].value_counts()

df = df[df['Employment'] == 'Employed, full-time']
df.drop(['Employment'], axis=1, inplace=True)
df.info()

df['Country'].value_counts()


def shorten_countries(categories, cutoff):
    categorical_map = {}
    for i in range(len(categories)):
        if categories.values[i] >= cutoff:
            categorical_map[categories.index[i]] = categories.index[i]
        else:
            categorical_map[categories.index[i]] = 'Other'
    return categorical_map


country_map = shorten_countries(df.Country.value_counts(), 400)
df['Country'] = df['Country'].map(country_map)
df['Country'].value_counts()

fig, ax = plt.subplots(1, 1, figsize=(12, 4))
df.boxplot('Salary', 'Country', ax=ax)

Q1 = df['Salary'].quantile(0.25)
Q3 = df['Salary'].quantile(0.75)
IQR = Q3 - Q1
df = df[(df['Salary'] >= Q1 - 1.5 * IQR) & (df['Salary'] <= Q3 + 1.5 * IQR)]

df['YearsCodePro'].unique()


def clean_exp(x):
    if x == 'Less than 1 year':
        return 0.5
    elif x == 'More than 50 years':
        return 50
    return float(x)


df['YearsCodePro'] = df['YearsCodePro'].apply(clean_exp)

df['EdLevel'].unique()


def clean_ed(x):
    if 'Bachelor’s degree' in x:
        return 'Bachelor’s degree'
    elif 'Master’s degree' in x:
        return 'Master’s degree'
    elif 'Professional degree' in x:
        return 'Post grad'
    return 'No degree'


df['EdLevel'] = df['EdLevel'].apply(clean_ed)

df['EdLevel'].unique()

cleaned_df = df.copy()

from sklearn.preprocessing import LabelEncoder

le_ed = LabelEncoder()
df['EdLevel'] = le_ed.fit_transform(df['EdLevel'])
df['EdLevel'].unique()

# df = pd.get_dummies(df, columns = ['Country'], drop_first = True)

le_country = LabelEncoder()
df['Country'] = le_country.fit_transform(df['Country'])
df['Country'].unique()



x = df.drop(['Salary'], axis=1)
y = df['Salary']

from sklearn.ensemble import GradientBoostingRegressor

gb_reg = GradientBoostingRegressor(learning_rate=0.1)

from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error

cv_scores = cross_val_score(gb_reg, x, y, cv=3, scoring='neg_mean_squared_error')

mse_scores = -cv_scores

# Print the mean and standard deviation of the cross-validation scores
print(f'Mean MSE: {np.sqrt(mse_scores.mean())}')
print(f'Standard Deviation MSE: {mse_scores.std()}')

gb_reg.fit(x, y)

import pickle

data = {'model': gb_reg, 'le_country': le_country, 'le_education': le_ed}
with open('saved_steps.pkl', 'wb') as file:
    pickle.dump(data, file)

with open('saved_steps.pkl', 'rb') as file:
    data = pickle.load(file)

regressor_load = data['model']
le_country = data['le_country']
le_education = data['le_education']

print(regressor_load.predict(np.array([[1, 1, 15]])))

print(cleaned_df['Country'].head())



